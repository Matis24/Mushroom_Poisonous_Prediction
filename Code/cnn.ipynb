{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the dataset of 15 family of mushroom\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import Dataset\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:/Users/mbrei/OneDrive/Bureau/ChampIA/Data/data_image\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a class to get the path of each image according to family and data type to transform it in tensors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MushroomDataset(Dataset):\n",
    "        def __init__(self, root_dir, data_type, transform=None):\n",
    "                \"\"\"\n",
    "                Choisir un répertoire racine et une transformation à appliquer aux images\n",
    "                \"\"\"\n",
    "                self.root_dir = root_dir\n",
    "                self.data_type = data_type \n",
    "                self.transform = transform\n",
    "                self.data = []\n",
    "                self.classes = {}\n",
    "                self._load_images()\n",
    "                \n",
    "        def _load_images(self):\n",
    "                \"\"\"\n",
    "                Récupérer les chemins de chaque image via différents dossiers avec l'étiquette de la famille de champignons\n",
    "                \"\"\"\n",
    "                class_idx = 0\n",
    "                for family_name in os.listdir(self.root_dir):\n",
    "                        family_dir = os.path.join(self.root_dir, family_name)\n",
    "                        if os.path.isdir(family_dir):\n",
    "                                data_type_dir = os.path.join(family_dir, 'data', self.data_type, family_name).replace('\\\\', '/')\n",
    "                                data_type_dir_champ = os.path.join(family_dir, 'data', self.data_type, f\"mushrooms {family_name}\").replace('\\\\', '/')\n",
    "                                if os.path.exists(data_type_dir):\n",
    "                                        target_dir = data_type_dir\n",
    "                                elif os.path.exists(data_type_dir_champ):\n",
    "                                        target_dir = data_type_dir_champ\n",
    "                                else:\n",
    "                                        continue\n",
    "                                if family_name not in self.classes:\n",
    "                                        self.classes[family_name] = class_idx\n",
    "                                        class_idx += 1\n",
    "                                for img_file in os.listdir(target_dir):\n",
    "                                        img_path = os.path.join(target_dir, img_file).replace('\\\\', '/')\n",
    "                                        if img_file.lower().endswith(('.jpg')):\n",
    "                                                self.data.append((img_path, family_name))\n",
    "        \n",
    "        def __len__(self):\n",
    "                return len(self.data)\n",
    "        \n",
    "        def __getitem__(self, idx):\n",
    "                img_path, family_name = self.data[idx]\n",
    "                image = Image.open(img_path).convert(\"RGB\")\n",
    "                \n",
    "                if self.transform:\n",
    "                        image = self.transform(image)\n",
    "                \n",
    "                # Convertir le nom de famille en index numérique\n",
    "                label = self.classes[family_name]\n",
    "                \n",
    "                return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data with only train\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "train_data = MushroomDataset(root_dir=path, data_type='train', transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.8471, 0.7647, 0.7608,  ..., 0.4745, 0.3922, 0.3176],\n",
       "          [0.7843, 0.7098, 0.7765,  ..., 0.3529, 0.3333, 0.2353],\n",
       "          [0.7765, 0.7294, 0.6471,  ..., 0.4824, 0.4275, 0.3765],\n",
       "          ...,\n",
       "          [0.5294, 0.5647, 0.3843,  ..., 0.5294, 0.3686, 0.2275],\n",
       "          [0.3373, 0.3216, 0.3804,  ..., 0.1725, 0.1451, 0.4275],\n",
       "          [0.3020, 0.2157, 0.1216,  ..., 0.3294, 0.4706, 0.5059]],\n",
       " \n",
       "         [[0.8353, 0.7176, 0.6706,  ..., 0.4078, 0.3686, 0.3216],\n",
       "          [0.7569, 0.6549, 0.6784,  ..., 0.2588, 0.2667, 0.1843],\n",
       "          [0.7294, 0.6549, 0.5451,  ..., 0.3569, 0.3059, 0.2510],\n",
       "          ...,\n",
       "          [0.3373, 0.3765, 0.1882,  ..., 0.4784, 0.2667, 0.0706],\n",
       "          [0.1725, 0.1569, 0.2196,  ..., 0.1216, 0.0667, 0.3216],\n",
       "          [0.1569, 0.0784, 0.0078,  ..., 0.2549, 0.4196, 0.4824]],\n",
       " \n",
       "         [[0.6745, 0.6314, 0.6392,  ..., 0.3294, 0.3137, 0.2902],\n",
       "          [0.6471, 0.6039, 0.6627,  ..., 0.2510, 0.2902, 0.2235],\n",
       "          [0.6824, 0.6392, 0.5490,  ..., 0.4000, 0.3765, 0.3412],\n",
       "          ...,\n",
       "          [0.2078, 0.2353, 0.0431,  ..., 0.4549, 0.2706, 0.1020],\n",
       "          [0.1255, 0.0941, 0.1412,  ..., 0.0980, 0.0392, 0.2863],\n",
       "          [0.1882, 0.0941, 0.0000,  ..., 0.2314, 0.3529, 0.3804]]]),\n",
       " 0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformation des images pour les amener à la bonne forme et les normaliser\n",
    "transform = transforms.Compose([\n",
    "  transforms.Resize((128, 128)),  # Assurer que l'image est bien de taille 128x128\\n\",\n",
    "  transforms.ToTensor(),  # Convertir l'image en un tenseur\\n\",\n",
    "  transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalisation\\n\",\n",
    "  ]),\n",
    "# Supposons que train_data est un objet Dataset personnalisé, donc on l'enveloppe dans un DataLoader\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "class SimpleCNN(nn.Module):\n",
    "\n",
    "        def __init__(self, num_classes):\n",
    "            super(SimpleCNN, self).__init__()\n",
    "            \n",
    "            # Définir les couches du CNN\n",
    "            self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "            self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "            self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "            \n",
    "            # MaxPooling pour réduire la taille de l'image\n",
    "            self.pool = nn.MaxPool2d(2, 2)\n",
    "            \n",
    "            # Couches Fully Connected\n",
    "            self.fc1 = nn.Linear(64 * 16 * 16, 512)  # Assurez-vous que les dimensions correspondent\n",
    "            self.fc2 = nn.Linear(512, num_classes)  # Nombre de classes\n",
    "            \n",
    "        def forward(self, x):\n",
    "            # Appliquer les convolutions et les max pooling\n",
    "            x = self.pool(torch.relu(self.conv1(x)))\n",
    "            x = self.pool(torch.relu(self.conv2(x)))\n",
    "            x = self.pool(torch.relu(self.conv3(x)))\n",
    "            # Applatir l'image pour la passer dans les couches fully connected\n",
    "            x = x.view(-1, 64 * 16 * 16)\n",
    "            \n",
    "            # Appliquer les couches fully connected\n",
    "            x = torch.relu(self.fc1(x))\n",
    "            x = self.fc2(x)\n",
    "            \n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Époque 1/10, Perte : 2.1998, Précision : 24.73%\n",
      "Époque 2/10, Perte : 1.8576, Précision : 37.92%\n",
      "Époque 3/10, Perte : 1.6185, Précision : 46.17%\n",
      "Époque 4/10, Perte : 1.3321, Précision : 56.04%\n",
      "Époque 5/10, Perte : 0.9745, Précision : 68.17%\n",
      "Époque 6/10, Perte : 0.5321, Précision : 82.83%\n",
      "Époque 7/10, Perte : 0.2089, Précision : 93.49%\n",
      "Époque 8/10, Perte : 0.1066, Précision : 97.21%\n",
      "Époque 9/10, Perte : 0.0511, Précision : 98.58%\n",
      "Époque 10/10, Perte : 0.0379, Précision : 98.98%\n"
     ]
    }
   ],
   "source": [
    "# Initialiser le modèle avec le nombre de classes\n",
    "num_classes = len(train_data.classes)\n",
    "model = SimpleCNN(num_classes=num_classes)\n",
    "# Définir la fonction de perte et l'optimiseur\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Définir l'appareil (GPU ou CPU)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "# Entraîner le modèle\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Mode entraînement\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        # Zero gradients\n",
    "        optimizer.zero_grad()\n",
    "        # Passer les entrées dans le modèle\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # Calculer la perte\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # Calculer la précision\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        running_loss += loss.item()\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    accuracy = 100 * correct / total\n",
    "    \n",
    "    print(f\"Époque {epoch+1}/{num_epochs}, Perte : {epoch_loss:.4f}, Précision : {accuracy:.2f}%\")\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"mushroom_cnn.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
